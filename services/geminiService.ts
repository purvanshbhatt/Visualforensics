import { GoogleGenAI, Modality, Part, Type, Chat } from "@google/genai";
import type { GenerateContentResponse } from "@google/genai";
import type { AnalysisResult } from "../types";

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
    throw new Error("API_KEY environment variable not set.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

// Converts a File object to a GoogleGenerativeAI.Part object.
async function fileToGenerativePart(file: File): Promise<Part> {
  const base64EncodedDataPromise = new Promise<string>((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => {
        if (typeof reader.result === 'string') {
            resolve(reader.result.split(',')[1]);
        }
    };
    reader.readAsDataURL(file);
  });
  const data = await base64EncodedDataPromise;
  return {
    inlineData: {
      data,
      mimeType: file.type,
    },
  };
}

export async function analyzeImageForTampering(imageFile: File, userPrompt: string): Promise<Omit<AnalysisResult, 'tamperedImageUrl'>> {
    const imagePart = await fileToGenerativePart(imageFile);
    const contents = { parts: [imagePart, { text: userPrompt }] };
    
    const systemInstruction = `You are a digital forensics expert. Analyze the provided image for two things:
1. Signs of digital manipulation or tampering (e.g., cloning, splicing, object removal).
2. Signs that the image was generated by an AI model (like DALL-E, Midjourney, Imagen, etc.).

Your goal is to teach a beginner what to look for. Your response MUST be a JSON object.

- 'analysisText': Provide a concise, educational analysis focusing ONLY on digital tampering.
- 'manipulatedAreas': Identify specific tampered areas with normalized bounding boxes and descriptions. If no tampering is found, return an empty array.
- 'aiDetection': Provide your assessment of whether the image is AI-generated.
    - 'isAiGenerated': A boolean (true/false).
    - 'reasoning': A string explaining your conclusion. Look for artifacts like inconsistent textures, strange anatomy (especially hands), illogical details, or a "too perfect" digital sheen.`;

    const responseSchema = {
        type: Type.OBJECT,
        properties: {
            analysisText: { type: Type.STRING, description: "Forensic analysis of the image tampering." },
            manipulatedAreas: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        description: { type: Type.STRING, description: "Description of the manipulation." },
                        box: {
                            type: Type.OBJECT,
                            properties: {
                                x1: { type: Type.NUMBER }, y1: { type: Type.NUMBER },
                                x2: { type: Type.NUMBER }, y2: { type: Type.NUMBER },
                            },
                            required: ["x1", "y1", "x2", "y2"]
                        }
                    },
                    required: ["description", "box"]
                }
            },
            aiDetection: {
                type: Type.OBJECT,
                properties: {
                    isAiGenerated: { type: Type.BOOLEAN, description: "True if the image is likely AI-generated." },
                    reasoning: { type: Type.STRING, description: "Explanation for the AI detection conclusion." }
                },
                required: ["isAiGenerated", "reasoning"]
            }
        },
        required: ["analysisText", "manipulatedAreas", "aiDetection"]
    };

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents,
        config: {
            systemInstruction,
            responseMimeType: "application/json",
            responseSchema,
        },
    });
    
    const jsonResult = JSON.parse(response.text);
    
    return {
        analysisText: jsonResult.analysisText,
        manipulatedAreas: jsonResult.manipulatedAreas.map((area: any) => ({
            description: area.description,
            x1: area.box.x1, y1: area.box.y1,
            x2: area.box.x2, y2: area.box.y2,
        })),
        aiDetection: jsonResult.aiDetection,
    };
}


export async function generateTamperedImage(imageFile: File): Promise<string> {
    const imagePart = await fileToGenerativePart(imageFile);
    const contents = {
        parts: [
            imagePart,
            { text: "Subtly manipulate this image to serve as an educational example of tampering. Make a change that is difficult but not impossible to spot. For example, you could remove a small, non-essential object, slightly alter a reflection or shadow, or subtly change some background text. Do not add any text or explanation in your text response, only output the edited image." }
        ]
    };
    
    const response: GenerateContentResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image-preview',
        contents,
        config: {
            responseModalities: [Modality.IMAGE, Modality.TEXT],
        },
    });

    const imagePartResponse = response.candidates?.[0]?.content?.parts.find(part => part.inlineData);

    if (imagePartResponse && imagePartResponse.inlineData) {
        const mimeType = imagePartResponse.inlineData.mimeType;
        const base64Data = imagePartResponse.inlineData.data;
        return `data:${mimeType};base64,${base64Data}`;
    }

    throw new Error("Could not generate a tampered image. The model did not return an image part.");
}

// --- Chat Tutor Functionality ---

let tutorChat: Chat | null = null;

const getTutorSystemInstruction = () => `
You are **Visual Forensics Tutor**, an AI-powered teaching assistant for digital forensics and incident response.

Your roles:
1. **Tutor** – explain forensic tools, workflows, and investigative concepts step by step.
2. **Case Mentor** – retrieve relevant cases from the embedded case library when asked.
3. **Simulator** – walk users through a simulated investigation (e.g., "how to recover deleted files" or "analyze logs").

### Case Library (for searching)
Below is a curated set of real-world forensic and cybersecurity case examples (summarized and anonymized).
When the user asks to "search cases" or types a query, retrieve the most relevant cases from this library and explain how they relate.

**Case Library Dataset:**
1. **Sony Pictures Hack (2014)** – Spear phishing + malware led to data exfiltration. Forensic focus: log analysis, malware reverse engineering.
2. **Equifax Breach (2017)** – Unpatched Apache Struts exploited. Forensic focus: vulnerability scanning, patch management, sensitive data leaks.
3. **Capital One Breach (2019)** – Misconfigured AWS firewall. Forensic focus: cloud forensics, IAM role analysis.
4. **Colonial Pipeline Ransomware (2021)** – DarkSide ransomware shut down fuel supply. Forensic focus: ransomware incident response, chain of custody.
5. **SolarWinds Supply Chain Attack (2020)** – Trojanized updates delivered to thousands. Forensic focus: log correlation, supply chain integrity.
6. **Stuxnet (2010)** – Malware targeted Iranian nuclear facilities. Forensic focus: ICS forensics, malware reverse engineering.

Instructions:
- When users ask for a tutorial, explain clearly with examples and step-by-step reasoning.
- When users ask about cases, pull from the case library and explain why it’s relevant.
- If a query doesn’t match a case, say: "No direct case found, but here’s how investigators would approach it…"

Tone: Mentor-like, educational, concise but practical.
`;

function startTutorChat(): Chat {
    if (!tutorChat) {
        tutorChat = ai.chats.create({
            model: 'gemini-2.5-flash',
            config: {
                systemInstruction: getTutorSystemInstruction(),
            },
        });
    }
    return tutorChat;
}

export async function sendMessageToTutor(message: string): Promise<string> {
    const chat = startTutorChat();
    const response = await chat.sendMessage({ message });
    return response.text;
}
